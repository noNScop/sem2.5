{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibr4spZjXcCE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r7Uj7lhXxdD"
      },
      "source": [
        "# Questionaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11d4y6gXZBXC"
      },
      "source": [
        "1) Implement a single neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AP9FBDrTZ2BE"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(3)\n",
        "w = torch.randn(3)\n",
        "b = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AwDR2wE0ZsH-"
      },
      "outputs": [],
      "source": [
        "def neuron(x, w, b):\n",
        "    return sum(wi * xi for wi, xi in zip(w, x)).item() + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c_sQ4bva_d-",
        "outputId": "38073536-10f4-43fd-9dd0-87a9d271edb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.9662, -0.2524,  0.0082])\n",
            "tensor([-0.1280,  0.8786,  0.6314])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0350211560726166"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x)\n",
        "print(w)\n",
        "neuron(x, w, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UFkjwxmb5SM"
      },
      "source": [
        "2) Implement ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n5-k-l78b-i7"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return x if x >= 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_BNFyicTXd"
      },
      "source": [
        "3) Write the Python code for a dense layer in terms of matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j7cHTNDDdSkv"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(2, 3)\n",
        "w = torch.randn(2, 3)\n",
        "b = tensor((1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0Pq9lbV4Xm0I"
      },
      "outputs": [],
      "source": [
        "def dense_layer(x, w, b):\n",
        "    return x @ w.t() + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odqp7V5wZI5W",
        "outputId": "885f3a86-4a03-4e19-e10d-2a575a009bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.5692, -0.4413,  0.1623],\n",
            "        [-0.6647,  0.0241, -1.1251]])\n",
            "tensor([[-0.9437, -0.3869,  0.2552],\n",
            "        [-0.7195,  1.5699, -0.5990]])\n",
            "tensor([1, 2])\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1.7493, 1.6196],\n",
              "        [1.3307, 3.1901]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x)\n",
        "print(w)\n",
        "print(b)\n",
        "print()\n",
        "dense_layer(x, w, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQLXpI3Md1h-"
      },
      "source": [
        "4) Write the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnFj0yPwdgBw",
        "outputId": "1b21055f-e80c-4341-fe2a-a32307968d36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[tensor(1.7493), tensor(1.6196)], [tensor(1.3307), tensor(3.1901)]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def dense_layer(x, w, b):\n",
        "    out = []\n",
        "    for batch in x:\n",
        "        b_out = []\n",
        "        for neur, bi in zip(w, b):\n",
        "            b_out.append(sum(xi * wi for xi, wi in zip(batch, neur)) + bi)\n",
        "\n",
        "        out.append(b_out)\n",
        "\n",
        "    return out\n",
        "\n",
        "dense_layer(x, w, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu6R26VikPTH"
      },
      "source": [
        "11) Write the PyTorch code to test whether every element of a is greater than the corresponding element of b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x7QetjQfvRx",
        "outputId": "0bb2ca2e-79f7-4961-e328-04f6f3b22570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.9407, 0.3795, 0.7352])\n",
            "tensor([0.0934, 0.4565, 0.1057])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand(3)\n",
        "b = torch.rand(3)\n",
        "print(f'{a}\\n{b}')\n",
        "(a > b).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ZnNAXSOZ5D"
      },
      "source": [
        "23) Implement matmul using Einstein summation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qlbRsSPnkgx4"
      },
      "outputs": [],
      "source": [
        "def matmul(a, b):\n",
        "    return torch.einsum('ij,jk->ik', a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfdM4438k6oM",
        "outputId": "d5c3c0f2-5b4c-49b0-d088-d8e0bb8d7608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 4],\n",
              "        [10]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tensor([[1, 2], [3, 4]])\n",
        "b = tensor([[2], [1]])\n",
        "matmul(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH6vuzKT3V7n"
      },
      "source": [
        "39) Write nn.Linear from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bXB1EN6S3ZnT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AlBHaZpM3iO3"
      },
      "outputs": [],
      "source": [
        "class LinearLayer(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super().__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_out, n_in) * sqrt(1/n_in))\n",
        "        self.b = nn.Parameter(torch.zeros(n_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x @ self.w.t() + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgOITvIB-SLE"
      },
      "source": [
        "# Further research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RS3PKJ3-WM5"
      },
      "source": [
        "# 1) Implement ReLU as a torch.autograd.Function and train a model with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-nvtp4D-cnU"
      },
      "source": [
        "I will train a model with it in point 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KIBP89sr6wJh"
      },
      "outputs": [],
      "source": [
        "class MyReLUFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        out = x.clamp_min(0)\n",
        "        ctx.save_for_backward(out)\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):\n",
        "        out, = ctx.saved_tensors\n",
        "        return grad_out * (out > 0).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KpXRGvWp3v4p"
      },
      "outputs": [],
      "source": [
        "class MyReLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return MyReLUFunction.apply(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sppcsy7-AgBM"
      },
      "source": [
        "# 2) Learn about the unfold method in PyTorch, and use it along with matrix multiplication to implement your own 2D convolution function. Then train a CNN that uses it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xl-RNaByx1ee"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iw0XzZq2go3",
        "outputId": "4c010afc-18f1-43bb-dd28-bebe2af9d1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded tensor shape: torch.Size([2, 3, 5, 5])\n",
            "Final shape of the input: torch.Size([2, 1, 3, 4, 4, 2, 2])\n",
            "Final shape of the kernel: torch.Size([1, 3, 3, 1, 1, 2, 2])\n",
            "torch.Size([2, 3, 4, 4])\n"
          ]
        }
      ],
      "source": [
        "# logic behind convolution - demonstration\n",
        "input = torch.rand(2, 3, 3, 3)\n",
        "bias = tensor((10000, 5000, 2000))\n",
        "\n",
        "# Define padding: (pad_left, pad_right, pad_top, pad_bottom)\n",
        "padding = [1]*4  # Adding 1 pixel of padding on all sides\n",
        "\n",
        "# Apply padding to the input tensor\n",
        "padded = F.pad(input, padding)\n",
        "print(f\"Padded tensor shape: {padded.shape}\")\n",
        "\n",
        "# unfold on 2 last dimensions as we will slide on them, set stride to 1 and kernel size to 2\n",
        "unfolded_input = padded.unfold(2, 2, 1).unfold(3, 2, 1)\n",
        "# unsqueeze after 2nd coordinate, to get the shape: batch_size x empty x in_channels x new_height x new_width x kernel_size x kernel_size\n",
        "unfolded_input = unfolded_input.unsqueeze(1)\n",
        "print(f\"Final shape of the input: {unfolded_input.shape}\")\n",
        "\n",
        "# initialise kernel with shape: out_channels x in_channels x kernel_size x kernel_size\n",
        "kernel = torch.rand(3, 3, 2, 2)\n",
        "# change the shape to: empty x out_channels x in_channels x empty x empty x kernel_size x kernel_size\n",
        "kernel = kernel.unsqueeze(-3).unsqueeze(-3).unsqueeze(0)\n",
        "print(f\"Final shape of the kernel: {kernel.shape}\")\n",
        "\n",
        "# apply convolution, sum over in_channels x kernel_size x kernel_size\n",
        "b = (unfolded_input * kernel).sum(dim=(2, -2, -1)) + bias[None, :, None, None]\n",
        "print(b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Sxi7jkt4AYdQ"
      },
      "outputs": [],
      "source": [
        "class MyConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, bias=True, stride=1, padding=0):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding = in_channels, out_channels, kernel_size, stride, padding\n",
        "\n",
        "        # set the shape to: empty x out_channels x in_channels x empty x empty x kernel_size x kernel_size\n",
        "        self.kernel = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size).unsqueeze(-3).unsqueeze(-3).unsqueeze(0))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        padding = [self.padding] * 4\n",
        "        padded = F.pad(x, padding)\n",
        "\n",
        "        # unfold on 2 last dimensions as we will slide on them\n",
        "        unfolded_input = padded.unfold(2, self.kernel_size, self.stride).unfold(3, self.kernel_size, self.stride)\n",
        "        # unsqueeze after 2nd coordinate, to get the shape: batch_size x empty x in_channels x new_height x new_width x kernel_size x kernel_size\n",
        "        unfolded_input = unfolded_input.unsqueeze(1)\n",
        "\n",
        "        # apply convolution, sum over in_channels x kernel_size x kernel_size\n",
        "        out = (unfolded_input * self.kernel).sum(dim=(2, -2, -1))\n",
        "\n",
        "        if self.bias is not None:\n",
        "            out += self.bias[None, :, None, None]\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB4JpesR0Wx-"
      },
      "source": [
        "Let's train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KeU23LL50a8-"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3mqu9Opmv18T"
      },
      "outputs": [],
      "source": [
        "path = untar_data(URLs.MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g6uQU59d0l6m"
      },
      "outputs": [],
      "source": [
        "Path.BASE_PATH = path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW5mMl0u0qmF",
        "outputId": "914b85e0-3853-4c50-c6bf-02b721f6bade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aHhuNm4Z0tc6"
      },
      "outputs": [],
      "source": [
        "def get_dls(bs=64):\n",
        "    return DataBlock(\n",
        "        blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n",
        "        get_items=get_image_files,\n",
        "        splitter=GrandparentSplitter('training','testing'),\n",
        "        get_y=parent_label,\n",
        "        batch_tfms=Normalize()\n",
        "    ).dataloaders(path, bs=bs)\n",
        "\n",
        "dls = get_dls(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH7OMlma4XKq",
        "outputId": "cf8c99a8-c0ee-4a6b-8be0-0768a04e17d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([512, 1, 28, 28])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = dls.one_batch()\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "OAOSJj-a0ymu",
        "outputId": "dc27a975-5b22-4b06-cc7b-d094eada5e71"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFeCAYAAAAIWe2LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoiElEQVR4nO3deVhV1f4/8A9aCIhYhDiSIzmAFg6ZeJ0tSwOvE+ZQ5nBTc2jQbpp6y7pqPlkpWQ45lIWlojnlVfMmZgom16EUDZQcAHFWFEUB+f3x/fXps7ac5QHOYR8279fz9Dzvfc7Z5yyB82mvvddeyy0vLy+PAAAgX2XMbgAAgCtDkQQA0ECRBADQQJEEANBAkQQA0ECRBADQQJEEANBAkQQA0ECRBADQQJEEANCwVJE8fPgw9enTh+rUqUNeXl7k5+dHbdu2pQ0bNpjdNNDYu3cvjR49moKCgqh8+fL08MMPU0REBCUmJprdNLiHffv2UXh4OPn6+pKXlxcFBwdTZGSk2c1yqPvMboAjnTx5kq5du0aDBg2iatWq0Y0bN2j16tUUHh5OCxYsoJdeesnsJkI+Zs6cSbt27aI+ffpQkyZNKD09nebOnUtNmzaluLg4Cg4ONruJkI+tW7dSWFgYhYSE0JQpU8jb25uOHz9OKSkpZjfNodysPsFFbm4uNWvWjLKysujo0aNmNwfysXv3bmrevDm5u7vzY0lJSdS4cWPq3bs3ff311ya2DvKTkZFBjzzyCIWGhlJ0dDSVKWOpTqnCuv+y/69s2bIUEBBAV65cMbspYENoaKhSIImIAgMDKSgoiI4cOWJSq0Bn+fLldPbsWZo2bRqVKVOGMjMz6c6dO2Y3yyksWSQzMzPpwoULdPz4cfr444/pP//5D3Xq1MnsZkEB5OXl0dmzZ8nPz8/spkA+tm3bRj4+PpSamkr169cnb29v8vHxoZEjR1JWVpbZzXMoSxbJcePGUaVKlahevXo0fvx46tGjB82dO9fsZkEBREVFUWpqKvXt29fspkA+kpKSKCcnh7p3705dunSh1atX05AhQ2j+/Pk0ePBgs5vnUJY8J3n06FFKSUmhtLQ0WrlyJbm7u9O8efOocuXKZjcN7HD06FFq2bIlBQUF0c6dO6ls2bJmNwkM6tatS8nJyTRixAiaN28ePz5ixAhasGABJSYmUmBgoIktdBxLHkk2aNCAOnfuTC+88AJt3LiRrl+/TmFhYWTB/x9YTnp6OnXr1o0qVqxI0dHRKJAuytPTk4iI+vXrpzzev39/IiKKjY0t9jY5iyWLpFHv3r1p7969GHfn4q5evUrPPPMMXblyhTZv3kzVqlUzu0lgw5+/G2PvzN/fn4iILl++XOxtcpZSUSRv3rxJRP/3JQTXlJWVRWFhYZSYmEgbN26kRo0amd0k0GjWrBkREaWmpiqPp6WlERFRpUqVir1NzmKpInnu3Lm7HsvOzqZly5aRp6cnvnguKjc3l/r27UuxsbG0atUqatWqldlNgnuIiIggIqLFixcrjy9atIjuu+8+at++vQmtcg5L3XEzfPhwysjIoLZt21L16tUpPT2doqKi6OjRo/Thhx+St7e32U2EfIwbN47Wr19PYWFhdOnSpbsGjw8cONCkloEtISEhNGTIEFqyZAnl5ORQu3btKCYmhlatWkUTJ0601KkSS13d/vbbb2nx4sX022+/0cWLF6lChQrUrFkzGjNmDIWHh5vdPLChffv2tGPHDpvPW+hP1FKys7Np+vTptHTpUkpLS6OaNWvSqFGj6NVXXzW7aQ5lqSIJAOBoljonCQDgaCiSAAAaKJIAABookgAAGiiSAAAaKJIAABookgAAGiiSAAAaKJIAABookgAAGiiSAAAaKJIAABookgAAGpaaTxIAXJtcm3vv3r3Kc3LZ56lTp3IeN26c8xumgSNJAAANFEkAAA0USQAADZyTBACnOnDgAOcJEyZw3rJli819Tp8+zTknJ4fzffcVf8nCkSQAgAaKJACABhYCAwCHS05O5ly3bl3OZcuW5dyyZUtln+rVq3OW63lXqFDBGU20G44kAQA0UCQBADRwdRsAiuzYsWPKduPGjTnLK9Lvvvsu5/Hjxyv7yK54mTKuc/zmOi0BAHBBKJIAABou3d2+evUqZ3ljPBHRpk2bOP/xxx/57h8VFaVs//7775y9vLw4ywGuY8aMUfapWLFiAVoMxeXKlSucU1JSlOfWrl3L+dChQ/nu/8UXXyjbHh4ejmqapd2+fZvzmjVrOPfv39/mPjNnzuT8xhtvOKdhToQjSQAADRRJAAANFEkAAA2XOCeZnp7O+ZNPPuH88ccfc75165Zd7yVvIHJzc1Oek9s3b97k/Pbbb3O+fv26ss+0adM4yyEKUPz27dvHecmSJZw//fRT5XXG33t+jOeaFyxYUMTWlQ4ffPAB58mTJ3MeNGiQ8rq//e1vnIcNG+b8hjkRjiQBADRQJAEANEyZ4GLSpEnKtuzqXL582a73kDfN9+nTp8BtmDVrFmc5X51RRkYG5/Llyxf4c6BoYmNjOS9cuJDzl19+ydn4J2xPd7tHjx7K9urVqwvbRMvJzs5WtuPj4znLITzyNJkc5kNE1KtXLye1rvjhSBIAQANFEgBAw6lXty9dusS5RYsWnE+cOKE2QtwAHx4ezjksLIyzXG6SiKhGjRqc7b3qLLvVkZGR+T5uvPPCnq4bFI0cuTB79mzluc8//5zz8ePHOXfo0IGzsWu3detWzuvXr8/3M41zGcJfoqOjle2JEydylqef5OiTnj17Or9hJsGRJACABookAICGU7vbcmD2I488wvmll15SXvfss89yDgoKclp7li5dyvnGjRv5vuZf//qXsi0nwgDHkQP4z5w5w3nRokXK63x8fDh/8803nKtWrco5ICBA2Wfu3Lmc5emSZs2ace7bt29hmm1ZR48e5TxjxgzluZMnT3J+8MEHOXfr1o2zo09LJSQkcJZ/Hw8//LDyusDAQId+bn5wJAkAoIEiCQCggSIJAKBh6SVld+zYoWzLc5/ynKS/vz/nw4cPK/v4+vo6qXWl25NPPsl527ZtnOW5RiKiH374gbM8Xy3vxAkNDVX2kefH5O925cqVnFu3bq3sUxonLzl16hRnOfG0PPdLpP4M5UTWnTt3LvBnyslI5B07xufkpMq6SWuaNGnCWX7fHTlZNo4kAQA0UCQBADQs0d2WN+TPmTOHs3E4j7yzQw7t2bt3L+f69esr++COG+eQpztk18rooYce4vztt99ynjJlCufTp08r+wwdOpSznMjkgQceKExTLUWuFfX8889zXr58OWfjz+l///sf59q1a3PWfTfk54wePZqzHIaXlZVlc395+kN2qffv329zH3k6bcOGDTZfV1A4kgQA0ECRBADQcInlG+whb6wnUq+yvfXWW5zlMrS67oDs7smrpsZ58V5//XXOZcrg/ymOIk93yGy84lmnTh3O58+f5ywnJRk4cKCyz/z58znLyVNA/dnILrY8rbFixQplH/k7sNfPP//Med68eZxlN1reGUVE1LBhQ87NmzfnLL/TP/30k7KPcdkIZ8C3HgBAA0USAEDDpfsiciIMOUcg0d1XNP+kG3hqjzfffNPmc+PHjy/w+8FfZBdZXtmU84bGxMTY3F8Oat6yZQvnxx57zDENtCA5OQWRempKnuaQp6+Mc7faY8+ePcp2ly5dOFerVo2z/A6NGjXKrveWk5wYbwKQgoOD7Xq/gsKRJACABookAIAGiiQAgIZLn5P8/vvvORuHhtjy73//m7Nx7ZMqVapwlmunyPM2crgCkXrjf6tWrTjrzo2UZvK847lz55TnJk+ezPmLL77gbO95ZLmcqbwLA1TyuzJu3DjlOTkk6r333uMszyHa69q1a5zlejdERNWrV+f81VdfcW7atGmBP0dOCCzvuiJSJ0oZOXJkgd/bHjiSBADQQJEEANBw6QkuNm3axDkzM1N5rm7dupwLcwhvy1NPPaVsy7kOZXuefvpph31mSSfvhImLi+PcvXt3u/YvzLAt+d7//Oc/lefkaZHSSK4J07hxY+U5eWfNwYMHORuXUraHnFjmxRdfVJ6Tw3aMp7Bskd/xX375hbM87WZcjvqDDz7gLCffcCQcSQIAaKBIAgBouPTV7a5duxb7ZxonsZDdP3lXQWnrbl++fFnZll215557jrPxirY9PD09OdesWVN57vfff893n3Xr1nGW84ESqXMJhoSEFLg9Jd2QIUM4X7x4UXlO3lFW1CUr5CQxxjtuWrZsyVl2nSV5+oqIaPXq1ZwPHTrEWU6EIa/IE6l/O86CI0kAAA0USQAADZfubruaJ554wuwmOJ28wiivHEZGRiqvs2c1u+HDhyv79O7dm7P8Wcp9jKc7cnNzOcuVE3v27Mk5NTVV2Wfjxo2cS2N3Wy5TYiTnZpSDwcuVK8fZ2IWVvxP5+7h58yZn45IPcq5KmXXk34e8Ii5v3DBjORUcSQIAaKBIAgBooEgCAGi49B03xUWep3n00UeV5y5dusRZnoez0no3+/bt4zxs2DDOuuU7pREjRnDu06cP544dOzqgdflr0aIFZ/n7IyLauXMn58qVKzutDa5KTmrx0Ucf2bVPQEAAZ+PktfIcpVxrSt6NVhjGNW4GDBjA2ZWW/7XONx0AwAlQJAEANErtEKA7d+5wnj17Nmfj2jlynR0rdbGlBQsWcD5w4ABnOdyiW7duyj5yrZJ27do5r3E2GO+ygb9MnTqVs3EJ1vj4+Hz3kX/3ttaPMvL19eX88ssvK8/J01Zybkm5VKxxuV8zhvfYw5rfegAAB0GRBADQKLVXt9955x3OxpvmpZSUFM5Vq1Z1ZpNMIycTmDZtGudBgwZxNi7bKpfCANd1/fp1ZfvIkSOc5QQTbdu25SyvYBMRvfLKK5xDQ0M5f/rpp5wffPDBojfWReFIEgBAA0USAEDD5brb8qqzvBJ29uxZ5XU7duzgXK9evXzfS67cR0Q0ffp0zvIKoLxqLa/uEhE1atSIs6tefQMA58GRJACABookAIAGiiQAgIbL3XGza9cuznIdFX9/f+V1WVlZnGNiYjhv3ryZc3R0tLLPH3/8wblixYqc5WSuQUFBhWg1AFgVjiQBADRQJAEANFxuCFBSUhJneZO8bt0OydZ6K0TqXTb9+vXjbGsIEQAAjiQBADRQJAEANFyuuy3179+f84oVK+za59133+Xcq1cv5bnAwEDOZcuWLWLrAKA0wJEkAIAGiiQAgIZLd7cBAMyGI0kAAA0USQAADRRJAAANSxbJffv2UXh4OPn6+pKXlxcFBwdTZGSk2c0CO02bNo3c3NwoODjY7KaADTExMeTm5pbvf3FxcWY3z6Fcbhagotq6dSuFhYVRSEgITZkyhby9ven48ePKgl7gulJSUmj69OlUvnx5s5sCdhg7diy1aNFCecxqt/laqkhmZGTQCy+8QN26daPo6GhlWQYoGcaPH09PPPEE5ebm0oULF8xuDtxDmzZtqHfv3mY3w6ksVUWWL19OZ8+epWnTplGZMmUoMzNTWTMHXNtPP/1E0dHRNHv2bLObAgVw7dq1u9aTshJLFclt27aRj48PpaamUv369cnb25t8fHxo5MiRyiS94Hpyc3NpzJgxNGzYMGrcuLHZzQE7DR48mHx8fMjDw4M6dOhA8fHxZjfJ4SzV3U5KSqKcnBzq3r07DR06lGbMmEExMTH0ySef0JUrV+ibb74xu4lgw/z58+nkyZO0bds2s5sCdnB3d6devXpR165dyc/PjxISEmjWrFnUpk0b2r17N4WEhJjdRMfJs5A6derkEVHeiBEjlMeHDx+eR0R5iYmJJrUMdC5cuJDn6+ubN2vWLH6sXbt2eUFBQSa2CgoqKSkpz9PTM69Lly5mN8WhLNXd9vT0JCJ1Ql2iv2YTio2NLfY2wb1NnjyZfH19acyYMWY3BYqgXr161L17d9q+fTvl5uaa3RyHsVSRrFatGhERVa5cWXn8z0XELl++XOxtAr2kpCRauHAhjR07ltLS0ujEiRN04sQJysrKouzsbDpx4gRdunTJ7GaCnQICAuj27duUmZlpdlMcxlJFslmzZkRElJqaqjyelpZGRESVKlUq9jaBXmpqKt25c4fGjh1LtWvX5v/27NlDiYmJVLt2bWWOUHBtycnJ5OHhQd7e3mY3xWEsdeEmIiKC3n//fVq8eDF17NiRH1+0aBHdd9991L59e/MaB/kKDg6m77777q7HJ0+eTNeuXaM5c+ZQ3bp1TWgZ6Jw/f/6ug46DBw/S+vXr6ZlnnrHUGGXLTZU2dOhQWrJkCUVERFC7du0oJiaGVq1aRRMnTqTp06eb3TywU/v27enChQt06NAhs5sC+ejYsSN5enpSaGgo+fv7U0JCAi1cuJDuv/9+io2NpYYNG5rdRIexXJHMzs6m6dOn09KlSyktLY1q1qxJo0aNoldffdXspkEBoEi6tsjISIqKiqJjx45RRkYGVapUiTp16kRvv/225W5LtFyRBABwJOucOAAAcAIUSQAADRRJAAANFEkAAA0USQAADRRJAAANFEkAAA0USQAADRRJAAANFEkAAA0USQAADRRJAAANS8wnefr0ac61atXivGDBAuV1w4YNK64mAYBF4EgSAEADRRIAQANFEgBAwxLnJCU3NzfOy5cvV57DOUkAKCgcSQIAaKBIAgBoWK67jSV7AIrHxYsXOUdGRirPTZgwgbOnp2extckZcCQJAKCBIgkAoGGJ7vbatWs5y6vbUPIlJSVx/uqrrzi/9dZbnPfs2aPsM2jQIM7x8fGc/fz8nNHEUuWzzz7j/OGHH3L+448/lNdlZmZybtKkCecuXbpwrlChgl2f+f3333Pu1KmT8pyvr69d71EUOJIEANBAkQQA0Cix3W3ZDXvllVc4o7ttLXPnzuWcm5vL2d3dnfPu3buVfU6dOsX5yJEjnNu0aeOMJlrerVu3OC9atIizsYstffTRRw77/IoVK3J+/fXXleemTJnisM+xBUeSAAAaKJIAABookgAAGpY4JynPQ8r86KOPFmuboOjWrFmjbM+bN4/znDlzOF+/fp3zjBkzlH28vb05t2jRwtFNtLzk5GRlu23btpzT0tI4y9+HcfKYffv25Zv379/PuX379so+Xl5enLt168ZZfqc9PDzu2X5Hw5EkAIAGiiQAgEaJ7W5Ltia1mDhxYjG3BApDduFGjRqlPCeH/TRu3JjzDz/8wFne3UFE1L9/f85mdM9KoqysLM6tWrVSnjt//jznF154gfOYMWNsvl/r1q3zzSURjiQBADRQJAEANEpsdzsqKoqzravb/v7+xdomsJ/sRkdERHA+e/as8roBAwZwbtmyJeeXX37Z5nvXrVvXEU20PHknjRwhILvXREQ1atTgPH36dM7Hjh3jnJCQoOyza9eue35+lSpVlO0ePXpwlktDmw1HkgAAGiiSAAAabnklZL2Dq1evKtsNGzbknJ6ezlkewsurpuBaRo8ezVnOUVi5cmXldXIgspwP8vHHH+d88OBBZR/Z9WvQoEHRG2tRV65c4Vy/fn3Oxu62HCEgfwenT5/mbO/EMnL+R/k7JCKKiYnh/Oabb3KWoxUCAwPt+hxHwpEkAIAGiiQAgAaKJACARokZArRs2TJl+9y5c5zl+ZChQ4cWW5ugYNatW8f5888/5yx/fxs3blT2qVq1KuedO3dy/vXXXzkb1z3BeUj73L59m7McDmQk78Zp2rQp586dO+f7ONHdd+38qVGjRpyNS83269eP89SpUzmfPHmS85IlS2y201lwJAkAoIEiCQCgUWK628Y7MeTIJZmffPLJYmsT6MXGxirbw4cP55yTk8M5MjKSc7NmzWy+32+//Zbv48HBwYVtYqlmaziPPJVBpHaly5Urx7lMGcceYy1dupRz9erVOct5K42TZRTH6TUcSQIAaKBIAgBolJju9qFDh5RteUU0JCSEs62ralA8zpw5w7lLly7Kc3Lex7CwMM72dpnk1VgoOtldrlChAmez5n+Ud/bIpVfkZChyhAMRutsAAKZDkQQA0CgxE1wYr6TJ7na7du04//jjj8XWJvg/cqIEOYGBbtIDuSLfzZs3ORvnGHzggQc4N2nShPPhw4c5b968WdkHIxysRU568vTTTyvPffnll07/fBxJAgBooEgCAGigSAIAaLj0EKA9e/ZwNp7fkttyuEBhyMky4uPjbb6ua9euRfocK5FDfeTdEfae4q5du3a+jxv3t3Ves2LFipxL+pKlcDc5kfaNGzc4y3V1iguOJAEANFAkAQA0XLq7ffHiRc66bpytIR/ypn0iorVr13KWN9PLNVJ03T25RO0vv/zCOSAgwGbbrGr37t2cbXWJ7V33RHrqqaeU7SNHjnBOSUnhnJGRwdn4+583bx5nOWwISo6FCxdylndqtWnTptjbgiNJAAANFEkAAA2X7m5LuqvbkrxSXatWLZv7yG61nC/POKJfmj59OuexY8dy/u6772zuY1XGu1zyY1xG4cUXX+Tcp08fzj4+PpzlHTtERO+99x7nd955h/Nrr73GuWbNmso+zz77LOf//ve/nM1YjhTsJ0eWfP/995zlfKFyednigiNJAAANFEkAAI0SM8GFsXstJ7yQg8nl9P+LFy+2+R4LFizgPGzYMLvaILvl8or4hg0blNeVhkHn169f5yx/FnKw7/PPP6/sU5jp/m11t/ft28fZeDPBpUuXOMvlBsqXL1/gz3dlSUlJnOXg/rZt25rRnAKTV62JiBo2bMhZjmSYOHEi52nTpjm/YQY4kgQA0ECRBADQQJEEANAoMUOA/vGPfyjbS5Ys4SzPicnlMHXDhs6fP89506ZNNj9XvrfM8r1K49ASb29vznKCCUdPNiGHgkhyMl4j4zAiq+rZsyfn48ePc5bnKuXkI2aRkzLLYT5yGBeReh6yX79+nEeNGuW8xtkBR5IAABookgAAGiVmCJCcU46IaM6cOZwnTZrE2dZdNbrnCrNPTEwM55Iy5KIkkuubyOE8R48e5ezl5VWsbXIV48eP5yy/DzVq1OAsh88QqcsvBwUF5fu+ZcuWVbblkq62nDp1StmeOnUqZ7nulDzNZSSHeE2YMIGzu7v7PT/fmXAkCQCggSIJAKBRYrrbOsZ5I/8k56QjIjp06BBnuTREy5YtOcub6Y3kvIWtWrXifP/999vfWCgQucSszAcOHDChNa5r2bJlnOVEIoVRp04dZVsu/1sYcqkNeUW+Y8eOyuvkpCdmd7ElHEkCAGigSAIAaFiiuw3WVb9+/Xwf379/P+fSenVbkl9jubRGVFSU8rq4uLh89/n99985V61aVdlH3iwxYMCAfPd/7LHHbO4jR4h4eHjY/ke4KBxJAgBooEgCAGigSAIAaOCcJLg0W5Puyokb5N1PRHcPYYF7k8Po/Pz8lOc8PT2LuzkuBUeSAAAaKJIAABolZj5JKJ2ee+45zlu2bMn3NfJOHCicgIAAs5vgsnAkCQCggSIJAKCBq9sAABo4kgQA0ECRBADQQJEEANBAkQQA0ECRBADQQJEEANCwVJHcu3cvjR49moKCgqh8+fL08MMPU0REBCUmJprdNNB48cUXyc3NzeZ/qampZjcRDGJiYmz+vuTEvlZgqdsSZ86cSbt27aI+ffpQkyZNKD09nebOnUtNmzaluLg47SJfYJ7hw4dT586dlcfy8vJoxIgRVKtWLWXGH3AtY8eOpRYtWiiP1atXz6TWOEmehezatSvv1q1bymOJiYl55cqVyxswYIBJrYLC2LlzZx4R5U2bNs3spkA+tm/fnkdEeatWrTK7KU5nqe52aGjoXUtRBgYGUlBQEB05csSkVkFhLF++nNzc3Kh///5mNwXu4dq1a5STk2N2M5zGUkUyP3l5eXT27Nm7JhIF15WdnU0rV66k0NBQqlWrltnNAY3BgweTj48PeXh4UIcOHSg+Pt7sJjmcpc5J5icqKopSU1Pp3XffNbspYKctW7bQxYsXlZX5wLW4u7tTr169qGvXruTn50cJCQk0a9YsatOmDe3evZtCQkLMbqLDWHqCi6NHj1LLli0pKCiIdu7cSWXLljW7SWCH/v37U3R0NJ05c4Yeeughs5sDdjp27Bg1adKE2rZtS5s3bza7OQ5j2SKZnp5OrVu3puzsbIqLi6Nq1aqZ3SSww/Xr16ly5crUsWNH2rBhg9nNgQLq168frVmzhm7cuGGZgxJLnpO8evUqPfPMM3TlyhXavHkzCmQJsnbtWrpx4wa62iVUQEAA3b59mzIzM81uisNY7pxkVlYWhYWFUWJiIm3bto0aNWpkdpOgAKKiosjb25vCw8PNbgoUQnJyMnl4eJC3t7fZTXEYSx1J5ubmUt++fSk2NpZWrVpFrVq1MrtJUADnz5+nbdu2UY8ePcjLy8vs5oDG+fPn73rs4MGDtH79enrqqaeoTBnrlBZLHUmOGzeO1q9fT2FhYXTp0iX6+uuvlecHDhxoUsvAHitWrKCcnBx0tUuAvn37kqenJ4WGhpK/vz8lJCTQwoULycvLi95//32zm+dQlrpw0759e9qxY4fN5y30T7WkVq1aUXJyMqWlpVnmpL9VRUZGUlRUFB07dowyMjKoUqVK1KlTJ3r77bctd1uipYokAICjWefEAQCAE6BIAgBooEgCAGigSAIAaKBIAgBooEgCAGigSAIAaKBIAgBooEgCAGigSAIAaKBIAgBooEgCAGigSAIAaKBIAgBooEgCAGigSAIAaKBIAgBoWGKNmx49enDu3bs357CwMJv77N+/n/Mrr7zC+bfffrO5z5EjRzg/8sgjBW4nAJQ8OJIEANBAkQQA0LDEQmByZT03Nze79pH/bHv36dmzJ+eVK1fa2ToAKMlwJAkAoIEiCQCgUaq6202aNOH85JNPch4xYgTnH3/8Udln+PDhnP38/DgnJiZy9vHxKWCLAaCkwJEkAIAGiiQAgIYlBpNv376dc1xcHOfnnntOeZ2/vz9nDw+PfN+rUaNGNj/n/PnznBMSEjg/8cQT9jcWAO4pMzOTc3Z2Nmfj99bW99iRcCQJAKCBIgkAoIEiCQCgYYlzkm3bts03F8bWrVuVbTlCqlatWpxL+3nIc+fOcW7YsCHn8PBwzpMnT1b2qVGjBueUlBS7Pufw4cOc5UQmheHr65vv+xKp56vBPqdPn+a8du1a5Tk5GYz8TpUp89dx2d/+9jdln59//pnz5cuXOWdlZXH29vZW9mndujVnOcSva9eunJs3b277H2EHHEkCAGigSAIAaFjijpuiunDhAufGjRsrz8lhPzVr1uR8/Phx5zfMhQ0dOpTzsmXL7NpnypQpnN977z279rlz5w5n2VUrKmMX7Ntvv+Usf8+lkfFve/z48ZzlxC79+/fnvGbNGpvvV5jJZIpq0KBBnJcsWVKk98KRJACABookAICGJa5uF1VGRgZn2b02GjlyZHE0x7Ls7WIXh/j4eGV7165dnEtjd1suW9KhQwflOXml+fbt25y3bdtm13vLn2dgYCDnW7duKa+TV6TlpDXSvn37lO369etzjoqK4uzI5VVwJAkAoIEiCQCgUWq723IgrL3kYOjS5qefflK2N23a5JTPkd0xIiIvLy/O8spocnIyZ3m6xF4DBgxQtiMiIgr8HiWdHKT9+uuvc5bdayKiBg0acL7vvr9KxqlTpzgbu86SnG/V3d29cI21w6RJkzgb/w1FgSNJAAANFEkAAA0USQAAjVJ7x42cLGH9+vU2XyfPp/z666+cAwICnNOwEqIwd9x4enpyHjNmTL6vGTdunLJdrlw5zrt37+Y8Y8YMzjt37rTr81966SXOco0jIqK///3vdr2HlRw6dIjzo48+avN1cqiPcXhQaYAjSQAADRRJAAANSwwBunbtGucKFSrYtc+QIUM4y67zZ599prwuNjY239eVdnLSAznRgY7sOhvnErRFrnWybt06zvZ2saXy5ctzLo3dayM5f6OOXCvq008/5SxPWRjnebR1x0xJhCNJAAANFEkAAA2X7m7Luyp+/PFH5bnU1FTO8sb2evXq2fXeW7Zs4Szv5JBLNBCVzskO7CGXbJC5qORdIERqt9zW5CP333+/si2Xafj44485d+rUyRFNtIwqVarY9To532rfvn3zfY1xtMCzzz7LediwYZyLYwlYR8ORJACABookAICGyw0ml1edo6OjOd+4ccPmPoWZHt7WPsOHD1deJ6/mgfN1795d2d64cSNnW8s3PPbYY8r23r17Hd4uK8rNzeW8f/9+zsYRHt999x3nwkwmUrt2bc4rVqzgLFc3JLr7tImrwJEkAIAGiiQAgAaKJACAhinnJOXwHSKi4OBgzleuXOGsW0JU3v0i/wkpKSl2tcHWOUnjkrJyslk52QU4zoEDBzj36tVLee7EiROcbf09rFq1StnG3TSOdfPmTc5bt27lPGrUKM7Z2dnKPnK4lvyuPfjgg5zDwsKUfRYtWsTZlc5P4kgSAEADRRIAQKPYutuJiYmcX331VeU5eQgv18B4/vnnOQ8ePFjZp3nz5pwXLlzIeezYsXa1p27dupx1S8rK7rccJgEFJ++mkXduyHkN5bopRER37tzhLLvbX3zxBed+/fop++hO05Q2AwcOVLa//vprp3xOQkKCsi3n7jxz5gxnefrE6ODBg5zlKTiz4a8JAEADRRIAQMOp3W15xUveSSG710byDounn37a5uvkTfeVK1fmrLvjRnbfP/nkE85Lly7l/Nprr9ncf/v27ZzbtGlj83WQP3nXlL3zfsru9ocffshZLoEKthl/zvLumc6dOxdLG+TV8fDwcM7GSWtu377N2ZXmo8SRJACABookAICGU+eTtDUI1ahdu3acbXWxZfeaiKhly5b3/HzjDfTz5s3jLOe169atG2ddd3v16tWc0d2+N3m1koho165dnO29Ai3n9yyu7qGVyMHbROr3Sy67MWvWLM5+fn7KPkUdLSBXydTNzxofH8/Znu93ccGRJACABookAIAGiiQAgEax3XEzcuRIzvIOGSJ1aM3jjz/OecmSJZzHjBlj873lORM5Sa4c9W+v+fPnK9vyDh4vLy/OcXFxnI3nWeQ5mNJswoQJyrYcwmOvo0ePcpZ3SYF9jJNIbNq06Z77DB06VNl++eWXOcv1jOQSwTonT57kHBISwlkO3SNSz0nK5X/NhiNJAAANFEkAAI1i627LLrVx+Uk5iYRsjpz4QEeuyVGYLraO7OLJm/OxLs5fLl68yFku1Wv8uRiXi/1TtWrVOPv7+yvPYb2aojHO8yiHUf38888Ffr8aNWpwlkv36sihYPJ7I+ejJCKKjIwscHuKA44kAQA0UCQBADSKrbt969YtzsY5HxcvXsxZNkde/erRo4eyjzxUb9SokcPaabR582bO8s4cdLf/IrvLxvk4bQkMDOQslxk1Lp8BjpWZmcl56tSpnGfPns1ZLjXrCPI7LU+nHDt2THmdt7e3Qz/XUXAkCQCggSIJAKBhymqJxitun3/+Oedr165x7t27N2dXGEg8adIkzsuXL+ccGxurvK5KlSrF1qbiYpys4ptvvuEsTy/YuoJNpK42KSe7aNCggSOaCEUgV6yUf9tEROvWreOcnJzMWc71qRMREcFZ/q3Ye3XcbDiSBADQQJEEANBAkQQA0DDlnCSUDPKc0+XLl5Xnhg0bxlmuSyTJc5BERLVr1+YsJzOAkiM9PZ2zveck5RCxkghHkgAAGiiSAAAa6G6DTefOneMslwQmsq+7/M477yjbb7zxBmd3d/eiNQ6gmOBIEgBAA0USAEDDqUvKQskmu8RyHkEi291tOV+hvJpNZP/VUABXgiNJAAANFEkAAA10t8EmuerjzJkzledycnI4y8HkCQkJnI3zfHp4eDi6iQBOhyNJAAANFEkAAA0USQAADdxxAwCggSNJAAANFEkAAA0USQAADRRJAAANFEkAAA0USQAADRRJAAANFEkAAA0USQAADRRJAAANFEkAAA0USQAAjf8HkrohojlXN3wAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 400x400 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dls.show_batch(max_n=9, figsize=(4,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0wKpzRix1Bpu"
      },
      "outputs": [],
      "source": [
        "def conv(ni, nf, ks=3, act=True):\n",
        "    layers = [MyConv(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
        "    if act: layers.append(MyReLU())\n",
        "    layers.append(nn.BatchNorm2d(nf))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t98DO4e_1PF8"
      },
      "outputs": [],
      "source": [
        "def simple_cnn():\n",
        "    return sequential(\n",
        "        conv(1 ,8, ks=5),        #14x14\n",
        "        conv(8 ,16),             #7x7\n",
        "        conv(16,32),             #4x4\n",
        "        conv(32,64),             #2x2\n",
        "        conv(64,10, act=False),  #1x1\n",
        "        Flatten(),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nMWtp4Ak1D0V"
      },
      "outputs": [],
      "source": [
        "def fit(epochs=1, lr=0.06):\n",
        "    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n",
        "                    metrics=accuracy, cbs=ActivationStats(with_hist=True))\n",
        "    learn.fit_one_cycle(epochs, lr)\n",
        "    return learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A75fDk5h1_UJ"
      },
      "source": [
        "My custom ReLU and Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8Olgbvzc1u8w",
        "outputId": "508902a5-074c-4730-c2bb-58b568e525e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.391073</td>\n",
              "      <td>0.095549</td>\n",
              "      <td>0.971000</td>\n",
              "      <td>01:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.101941</td>\n",
              "      <td>0.069636</td>\n",
              "      <td>0.977500</td>\n",
              "      <td>01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.054913</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>0.987200</td>\n",
              "      <td>01:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.030633</td>\n",
              "      <td>0.030033</td>\n",
              "      <td>0.989900</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.016128</td>\n",
              "      <td>0.027338</td>\n",
              "      <td>0.990400</td>\n",
              "      <td>01:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn = fit(5, lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZdCWxufN1uxk"
      },
      "outputs": [],
      "source": [
        "def conv(ni, nf, ks=3, act=True):\n",
        "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
        "    if act: layers.append(nn.ReLU())\n",
        "    layers.append(nn.BatchNorm2d(nf))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFRln5Qp2Ftj"
      },
      "source": [
        "Pytorch deafult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Lq5E5JG21zNt",
        "outputId": "585b8148-e8e7-4add-9b58-f61c4f997a3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.178685</td>\n",
              "      <td>0.095457</td>\n",
              "      <td>0.969900</td>\n",
              "      <td>01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.077373</td>\n",
              "      <td>0.052988</td>\n",
              "      <td>0.982300</td>\n",
              "      <td>01:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048993</td>\n",
              "      <td>0.045788</td>\n",
              "      <td>0.984200</td>\n",
              "      <td>01:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.026380</td>\n",
              "      <td>0.991300</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.015460</td>\n",
              "      <td>0.022986</td>\n",
              "      <td>0.991600</td>\n",
              "      <td>01:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn = fit(5, lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEG8i6L3VOuR"
      },
      "source": [
        "# 3) Implement everything in this chapter by using NumPy instead of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s70G_hjme46n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fm1mXG8fvv-"
      },
      "source": [
        "## matmul I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "018OZTvAfIlx"
      },
      "outputs": [],
      "source": [
        "def matmul_torch(a,b):\n",
        "    ar,ac = a.shape # n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "    assert ac == br\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            for k in range(ac): c[i,j] += a[i,k] * b[k,j]\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6m9yJXOofMLZ"
      },
      "outputs": [],
      "source": [
        "def matmul_np(a,b):\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac == br\n",
        "    c = np.zeros((ar, bc))\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            for k in range(ac):\n",
        "                c[i,j] += a[i,k] * b[k,j]\n",
        "\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dxpeGFvIgjOS"
      },
      "outputs": [],
      "source": [
        "at = tensor([[1, 2, 3], [4, 5, 6]])\n",
        "bt = tensor([[7, 8], [9, 10], [11, 12]])\n",
        "an = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "bn = np.array([[7, 8], [9, 10], [11, 12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSOI43phg0va",
        "outputId": "aff14721-a95b-4077-baf7-82d4714b8a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 58.,  64.],\n",
            "        [139., 154.]])\n",
            "\n",
            "[[ 58.  64.]\n",
            " [139. 154.]]\n"
          ]
        }
      ],
      "source": [
        "print(matmul_torch(at,bt))\n",
        "print()\n",
        "print(matmul_np(an,bn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tAhmaDYEfzcd"
      },
      "outputs": [],
      "source": [
        "t1 = torch.randn(5,28*28)\n",
        "t2 = torch.randn(784,10)\n",
        "n1 = t1.numpy()\n",
        "n2 = t2.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtUnOKqqgD6q",
        "outputId": "6c7486ba-1ea6-4158-ece2-82822a34a069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "923 ms ± 65.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_torch(t1, t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz-pFyo_j1xa",
        "outputId": "33cf1cee-d172-43ce-c241-53f0988b1596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31.1 ms ± 567 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_np(n1, n2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rvsumHrkSRI"
      },
      "source": [
        "numpy is ~30x faster than pytorch here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCClC0CLkx6e"
      },
      "source": [
        "## Elementwise arithmetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFNpmCSgVlL5",
        "outputId": "7a5bee99-18bf-4157-d11b-bc754f1d0383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([12., 14.,  3.])\n",
            "tensor([False,  True,  True])\n",
            "tensor(False)\n",
            "tensor(True)\n",
            "9.666666984558105\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.,  4.,  9.],\n",
              "        [16., 25., 36.],\n",
              "        [49., 64., 81.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tensor([10., 6, -4])\n",
        "b = tensor([2., 8, 7])\n",
        "print(a + b)\n",
        "print(a < b)\n",
        "print((a < b).all())\n",
        "print((a != b).all())\n",
        "print((a + b).mean().item())\n",
        "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]])\n",
        "m*m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSB9rYG1lG1z",
        "outputId": "7a2daaed-b764-4ced-d01b-7ae0aa9b5b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12. 14.  3.]\n",
            "[False  True  True]\n",
            "False\n",
            "True\n",
            "9.666666666666666\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.],\n",
              "       [49., 64., 81.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([10., 6, -4])\n",
        "b = np.array([2., 8, 7])\n",
        "print(a + b)\n",
        "print(a < b)\n",
        "print(np.all(a < b))\n",
        "print(np.all(a != b))\n",
        "print(np.mean(a + b))\n",
        "m = np.array([[1., 2, 3], [4,5,6], [7,8,9]])\n",
        "m*m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_gD5CzHngsx"
      },
      "source": [
        "## matmul II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nIHDtfq-l6qL"
      },
      "outputs": [],
      "source": [
        "def matmul_torch(a,b):\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac == br\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc): c[i,j] = (a[i] * b[:,j]).sum()\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xHa0WiDqZT_4"
      },
      "outputs": [],
      "source": [
        "def matmul_np(a,b):\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac == br\n",
        "    c = np.zeros((ar, bc))\n",
        "    for i in range(ar):\n",
        "        for j in range(bc): c[i,j] = np.sum((a[i] * b[:,j]))\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CLIuxUamuY",
        "outputId": "db75b416-2e9c-4a2e-eb05-09213fa29c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 58.,  64.],\n",
            "        [139., 154.]])\n",
            "\n",
            "[[ 58.  64.]\n",
            " [139. 154.]]\n"
          ]
        }
      ],
      "source": [
        "print(matmul_torch(at,bt))\n",
        "print()\n",
        "print(matmul_np(an,bn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMLH-U7ja42G",
        "outputId": "0dfa5ace-2864-4a8c-da95-14e11142eec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.49 ms ± 577 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_torch(t1, t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxsCX1xDbAcj",
        "outputId": "02966e2c-a64a-43d7-98fd-fc51e7bd7a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "372 µs ± 16.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_np(n1, n2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR4ECQSIonTl"
      },
      "source": [
        "numpy is ~4x faster than pytorch here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yc19aiKo5kU"
      },
      "source": [
        "## Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plN5OAI0i2Xz"
      },
      "source": [
        "I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNHwZjJGdfl7",
        "outputId": "866ed1f6-7051-4f22-b578-ef2e99c75490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ True,  True, False])\n",
            "tensor([[-1.4652, -1.0989, -0.7326],\n",
            "        [-0.3663,  0.0000,  0.3663],\n",
            "        [ 0.7326,  1.0989,  1.4652]])\n",
            "torch.Size([3, 3]) torch.Size([3])\n",
            "tensor([[11., 22., 33.],\n",
            "        [14., 25., 36.],\n",
            "        [17., 28., 39.]])\n",
            "tensor([[11., 22., 33.],\n",
            "        [14., 25., 36.],\n",
            "        [17., 28., 39.]])\n"
          ]
        }
      ],
      "source": [
        "a = tensor([10., 6, -4])\n",
        "print(a > 0)\n",
        "\n",
        "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]])\n",
        "print((m - 5) / 2.73)\n",
        "\n",
        "c = tensor([10.,20,30])\n",
        "print(m.shape,c.shape)\n",
        "print(m + c)\n",
        "print(c + m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA_3NjGWeWFl",
        "outputId": "258aa59e-536a-4e54-b147-2c9530cef642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True  True False]\n",
            "tensor([[-1.4652, -1.0989, -0.7326],\n",
            "        [-0.3663,  0.0000,  0.3663],\n",
            "        [ 0.7326,  1.0989,  1.4652]])\n",
            "(3, 3) torch.Size([3])\n",
            "[[11. 22. 33.]\n",
            " [14. 25. 36.]\n",
            " [17. 28. 39.]]\n",
            "[[11. 22. 33.]\n",
            " [14. 25. 36.]\n",
            " [17. 28. 39.]]\n"
          ]
        }
      ],
      "source": [
        "an = np.array([10., 6, -4])\n",
        "print(an > 0)\n",
        "\n",
        "mn = np.array([[1., 2, 3], [4,5,6], [7,8,9]])\n",
        "print((m - 5) / 2.73)\n",
        "\n",
        "cn = np.array([10.,20,30])\n",
        "print(mn.shape,c.shape)\n",
        "print(mn + cn)\n",
        "print(cn + mn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b11yGrnUi5Kt"
      },
      "source": [
        "II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF43h4uzqQFT",
        "outputId": "dec9f1d1-cd40-4766-dbe6-230f78d1f43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[10., 20., 30.],\n",
            "        [10., 20., 30.],\n",
            "        [10., 20., 30.]])\n",
            " 10.0\n",
            " 20.0\n",
            " 30.0\n",
            "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 3]\n",
            "(0, 1) torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "print(c.expand_as(m))\n",
        "\n",
        "t = c.expand_as(m)\n",
        "print(t.storage())\n",
        "print(t.stride(), t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTi9n90RiqbN",
        "outputId": "6407cd58-9efa-4b02-e2fd-4584dab6cf7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10. 20. 30.]\n",
            " [10. 20. 30.]\n",
            " [10. 20. 30.]]\n",
            "(0, 8) (3, 3)\n"
          ]
        }
      ],
      "source": [
        "# no equivalent function to .storage()\n",
        "tn = np.broadcast_to(cn, mn.shape)\n",
        "print(tn)\n",
        "print(tn.strides, tn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GypXTT4vmyTq"
      },
      "source": [
        "8 represents 8 bytes, so it is equivalent to 1 in pytorch, as numpy is using 64 bit floats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH43T9EcjXV7"
      },
      "source": [
        "III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov31p9g-BtP4",
        "outputId": "660cd26b-b6aa-4c66-86a6-995d41441882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3]) torch.Size([3, 1])\n",
            "tensor([[11., 12., 13.],\n",
            "        [24., 25., 26.],\n",
            "        [37., 38., 39.]])\n"
          ]
        }
      ],
      "source": [
        "c = c.unsqueeze(1)\n",
        "print(m.shape,c.shape)\n",
        "print(c + m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmsk1S2KnCjB",
        "outputId": "fa445fc6-61f4-4cf3-b810-afa5c45ec84b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 3) (3, 1)\n",
            "tensor([[11., 12., 13.],\n",
            "        [24., 25., 26.],\n",
            "        [37., 38., 39.]])\n"
          ]
        }
      ],
      "source": [
        "tmp = cn\n",
        "cn = np.expand_dims(tmp, axis=1)\n",
        "print(mn.shape, cn.shape)\n",
        "print(c + m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf3fNQCnjYUJ"
      },
      "source": [
        "IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUzQQGvPEg9H",
        "outputId": "d5556e97-0b18-4465-b336-3d08c56eb498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 1]), torch.Size([1, 3, 1]), torch.Size([3, 1, 1]))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.shape, c[None,:].shape,c[:,None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQZyooRpcIe",
        "outputId": "938c8b4d-a028-49e0-8e9d-452f5a39d2f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3, 1), (1, 3, 1), (3, 1, 1))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cn.shape, cn[None, :].shape, cn[:, None].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUzDzCcyjcFl"
      },
      "source": [
        "V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UG92Ll4EiYJ",
        "outputId": "04ce9e10-9195-4b2c-d992-5d5d4f780610"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 1]), torch.Size([3, 1, 1]))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c[None].shape, c[...,None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHeM6KEqEkGI",
        "outputId": "3f06ba5b-7802-4016-ec00-bedc2cd26279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 3, 1), (3, 1, 1))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cn[None].shape, cn[..., None].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ngz7ZvWqabb"
      },
      "source": [
        "## matmul III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "EVqMQPosqeEo"
      },
      "outputs": [],
      "source": [
        "def matmul_torch(a,b):\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac == br\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "#       c[i,j] = (a[i,:]          * b[:,j]).sum() # previous\n",
        "        c[i]   = (a[i  ].unsqueeze(-1) * b).sum(dim=0)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "nkh6844W7Ris"
      },
      "outputs": [],
      "source": [
        "def matmul_np(a,b):\n",
        "    ar, ac = a.shape\n",
        "    br, bc = b.shape\n",
        "    assert ac == br\n",
        "    c = np.zeros((ar, bc))\n",
        "    for i in range(ar):\n",
        "        c[i] = (a[i][:, None] * b).sum(axis=0)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9PBMQ14p8vvp"
      },
      "outputs": [],
      "source": [
        "at = tensor([[1, 2, 3], [4, 5, 6]])\n",
        "bt = tensor([[7, 8], [9, 10], [11, 12]])\n",
        "an = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "bn = np.array([[7, 8], [9, 10], [11, 12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHJlnPw8ij7",
        "outputId": "04100bef-f0df-4ad7-b2b4-573a0f6c754c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 58.,  64.],\n",
            "        [139., 154.]])\n",
            "\n",
            "[[ 58.  64.]\n",
            " [139. 154.]]\n"
          ]
        }
      ],
      "source": [
        "print(matmul_torch(at,bt))\n",
        "print()\n",
        "print(matmul_np(an,bn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOLME6gW8mpA",
        "outputId": "cce49ece-40fc-4b06-9b59-adecd7f1b245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250 µs ± 14.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_torch(t1, t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhLMepOM81ph",
        "outputId": "be28b709-4eb1-407a-a23c-0dda0e69b52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172 µs ± 9.16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_np(n1, n2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_jaXRdT9zUp"
      },
      "source": [
        "the difference between numpy and pytorch is gone, and sometimes pytorch is even faster than numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPwozCj-qvV"
      },
      "source": [
        "## Einstein Summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ADMIHZG9Hny",
        "outputId": "dbeb8d6b-058e-450a-ed58-133decab79f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 611, 1637, 2935])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tensor([[1, 2], [3, 4], [5, 6]])\n",
        "b = tensor([[7, 8], [9, 10]])\n",
        "c = tensor([[11, 12], [13, 14], [15, 16]])\n",
        "torch.einsum('bi,ij,bj->b', a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQLF81u_0hC",
        "outputId": "029cc56f-667b-4cff-f78e-6b5cbb95573d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 611, 1637, 2935])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "b = np.array([[7, 8], [9, 10]])\n",
        "c = np.array([[11, 12], [13, 14], [15, 16]])\n",
        "np.einsum('bi,ij,bj->b', a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "EI-1Ur-t_FIp"
      },
      "outputs": [],
      "source": [
        "def matmul_torch(a,b): return torch.einsum('ik,kj->ij', a, b)\n",
        "def matmul_np(a,b): return np.einsum('ik,kj->ij', a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV7dr1Hf_aHC",
        "outputId": "ee63c515-8568-4727-e20f-a81d2ca31d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 58,  64],\n",
            "        [139, 154]])\n",
            "\n",
            "[[ 58  64]\n",
            " [139 154]]\n"
          ]
        }
      ],
      "source": [
        "print(matmul_torch(at,bt))\n",
        "print()\n",
        "print(matmul_np(an,bn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElfIhBwe_dLI",
        "outputId": "f0b91de9-fa27-4269-bd56-e76cfb2523e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33 µs ± 3.15 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_torch(t1, t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-u0JHln_fgz",
        "outputId": "ffffd665-25ca-49ca-c6d5-1134c9c747fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42.8 µs ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul_np(n1, n2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O699wupLV16"
      },
      "source": [
        "einsum for pytorch seems a little faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ47BNhTLeyT"
      },
      "source": [
        "## Matrix Multiplication final comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pu0H0FV_hmH",
        "outputId": "e9577d33-43cf-4b1c-f55c-c135f1d5b48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.5 µs ± 2.04 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit t1 @ t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v66_gPdMKvw",
        "outputId": "1fb1a53f-b38a-419b-d169-71428577a955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16.9 µs ± 2.48 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit n1 @ n2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7393t6oPMbye"
      },
      "source": [
        "again - pytorch is faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMevA-aiNUzO"
      },
      "source": [
        "Going any further doesn't make any sense, as there are no more new operations introduced"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
